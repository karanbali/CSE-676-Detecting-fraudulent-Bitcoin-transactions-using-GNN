{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56HpsDl19cCb"
      },
      "source": [
        "### Mounting Googel Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEU5a2b59eKV",
        "outputId": "bf890825-4ab3-45e8-cb81-9c6acf31a03b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXLGd_ha9jvT"
      },
      "source": [
        "### Importing Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQU5vMXImRuU",
        "outputId": "196c79e9-62be-434a-a05d-710a818e7485"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.dgl.ai/wheels/repo.html\n",
            "Collecting dgl-cu111\n",
            "  Downloading https://data.dgl.ai/wheels/dgl_cu111-0.7.2-cp37-cp37m-manylinux1_x86_64.whl (165.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 165.0 MB 36 kB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu111) (1.4.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu111) (2.23.0)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.7/dist-packages (from dgl-cu111) (2.6.3)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu111) (1.19.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu111) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu111) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu111) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu111) (3.0.4)\n",
            "Installing collected packages: dgl-cu111\n",
            "Successfully installed dgl-cu111-0.7.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using backend: pytorch\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "!pip install dgl-cu111 -f https://data.dgl.ai/wheels/repo.html\n",
        "\n",
        "import numpy as np\n",
        "import dgl\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import urllib.request\n",
        "import pandas as pd\n",
        "import dgl.data\n",
        "import dgl\n",
        "from dgl.data import DGLDataset\n",
        "import torch\n",
        "import os\n",
        "import itertools\n",
        "import dgl.nn as dglnn\n",
        "from dgl.nn import GraphConv\n",
        "from dgl.nn import GATConv\n",
        "\n",
        "\n",
        "from scipy.spatial import Delaunay\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dsRPmNOBfxe"
      },
      "source": [
        "### Reding CSV files defining the classes, edges and node feaures respectively. More details can be found at: https://www.kaggle.com/ellipticco/elliptic-data-set\n",
        "\n",
        "\n",
        "NOTE: Please change the path of the CSV files according to your directory structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "pv1ifoIEmiEC"
      },
      "outputs": [],
      "source": [
        "classes = pd.read_csv('/content/gdrive/MyDrive/Fall_21/BC_DL/elliptic_bitcoin_dataset/elliptic_txs_classes.csv')\n",
        "edges = pd.read_csv('/content/gdrive/MyDrive/Fall_21/BC_DL/elliptic_bitcoin_dataset/elliptic_txs_edgelist.csv')\n",
        "features = pd.read_csv('/content/gdrive/MyDrive/Fall_21/BC_DL/elliptic_bitcoin_dataset/elliptic_txs_features.csv',header=None).set_index(0,verify_integrity=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvLP9sunBi0k"
      },
      "source": [
        "### Filtering entries with unknown classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "voRRd6iYOy4B"
      },
      "outputs": [],
      "source": [
        "classes_filtered = classes\n",
        "classes_filtered = classes_filtered[classes_filtered['class'] != 'unknown']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmTvyY84Bl7A"
      },
      "source": [
        "### Spliting features into 2 sections: i) all entries with 1st feature value below 35 would be used for training ii) all entries with 2nd feature value above 35 would be used for testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vPba-bqDq-Vl"
      },
      "outputs": [],
      "source": [
        "features_train = features[features[1]<35]\n",
        "features_test = features[features[1]>=35]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RZJr6AyIX0E"
      },
      "source": [
        "### Creating Training & testing dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "FP5PUKdoACZX"
      },
      "outputs": [],
      "source": [
        "src = []\n",
        "dst = []\n",
        "feats = []\n",
        "labels = []\n",
        "\n",
        "id_cnt = 0\n",
        "\n",
        "id_dict = {}\n",
        "\n",
        "for index, row in edges.iterrows():\n",
        "  \n",
        "  if (len(classes_filtered.loc[classes_filtered['txId']==row['txId1']]['class'].values) != 0) and (len(classes_filtered.loc[classes_filtered['txId']==row['txId2']]['class'].values) != 0) and (row['txId1'] in features_train.index) and (row['txId2'] in features_train.index):\n",
        "    \n",
        "    key = row['txId1']\n",
        "    if key not in id_dict:\n",
        "        id_dict.update({key: id_cnt})\n",
        "        src.append(id_cnt)\n",
        "        feats.append(features.loc[key].to_numpy())\n",
        "\n",
        "        #print(\"labe\",int(classes_filtered.loc[classes_filtered['txId']==row['txId1']]['class'].values[0]))\n",
        "        labels.append(int(classes_filtered.loc[classes_filtered['txId']==row['txId1']]['class'].values[0])-1)\n",
        "       \n",
        "\n",
        "        \n",
        "        id_cnt += 1\n",
        "    else:\n",
        "        val = id_dict[key]\n",
        "        src.append(val)\n",
        "      \n",
        "\n",
        "    key = row['txId2']\n",
        "    if key not in id_dict:\n",
        "        id_dict.update({key: id_cnt})\n",
        "        dst.append(id_cnt)\n",
        "        feats.append(features.loc[key].to_numpy())\n",
        "        \n",
        "        #print(\"labe\",int(classes_filtered.loc[classes_filtered['txId']==row['txId2']]['class'].values[0]))\n",
        "        labels.append(int(classes_filtered.loc[classes_filtered['txId']==row['txId2']]['class'].values[0])-1)\n",
        "\n",
        "        id_cnt += 1\n",
        "    else:\n",
        "        val = id_dict[key]\n",
        "        dst.append(val)\n",
        "       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "CWtnE2gEDexj"
      },
      "outputs": [],
      "source": [
        "src_test = []\n",
        "dst_test = []\n",
        "feats_test = []\n",
        "labels_test = []\n",
        "\n",
        "id_cnt = 0\n",
        "\n",
        "id_dict_test = {}\n",
        "\n",
        "for index, row in edges.iterrows():\n",
        "  \n",
        "  if (len(classes_filtered.loc[classes_filtered['txId']==row['txId1']]['class'].values) != 0) and (len(classes_filtered.loc[classes_filtered['txId']==row['txId2']]['class'].values) != 0) and (row['txId1'] in features_test.index) and (row['txId2'] in features_test.index):\n",
        "    \n",
        "    key = row['txId1']\n",
        "    if key not in id_dict_test:\n",
        "        id_dict_test.update({key: id_cnt})\n",
        "        src_test.append(id_cnt)\n",
        "        feats_test.append(features.loc[key].to_numpy())\n",
        "        labels_test.append(int(classes_filtered.loc[classes_filtered['txId']==row['txId1']]['class'].values[0])-1)\n",
        "        id_cnt += 1\n",
        "    else:\n",
        "        val = id_dict_test[key]\n",
        "        src_test.append(val)\n",
        "      \n",
        "\n",
        "    key = row['txId2']\n",
        "    if key not in id_dict_test:\n",
        "        id_dict_test.update({key: id_cnt})\n",
        "        dst_test.append(id_cnt)\n",
        "        feats_test.append(features.loc[key].to_numpy())\n",
        "        labels_test.append(int(classes_filtered.loc[classes_filtered['txId']==row['txId2']]['class'].values[0])-1)\n",
        "        id_cnt += 1\n",
        "    else:\n",
        "        val = id_dict_test[key]\n",
        "        dst_test.append(val)\n",
        "       \n",
        "     \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8WrixzjIwFK"
      },
      "source": [
        "### Creating Training & Testing graphs using DGL APIs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0GeLJ4O8ZV84"
      },
      "outputs": [],
      "source": [
        "# Training Graph\n",
        "feats = np.array(feats)\n",
        "g = dgl.graph((src, dst))\n",
        "g.ndata['feat'] = torch.from_numpy(feats)\n",
        "g.ndata['label'] = torch.from_numpy(np.array(labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "XA7WuI10IY9k"
      },
      "outputs": [],
      "source": [
        "# Testing Graph\n",
        "feats_test = np.array(feats_test)\n",
        "g_test = dgl.graph((src_test, dst_test))\n",
        "g_test.ndata['feat'] = torch.from_numpy(feats_test)\n",
        "g_test.ndata['label'] = torch.from_numpy(np.array(labels_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywKNdN3UIFeq"
      },
      "source": [
        "### Defining GCN using DGL API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "OH-ThJYqwQKF"
      },
      "outputs": [],
      "source": [
        "class AML_GCN(nn.Module):\n",
        "    def __init__(self, input_feats, hidden_feats, output_feats):\n",
        "        super().__init__()\n",
        "        self.layer1 = dglnn.SAGEConv(\n",
        "            in_feats=input_feats, out_feats=hidden_feats, aggregator_type='mean')\n",
        "        self.layer2 = dglnn.SAGEConv(\n",
        "            in_feats=hidden_feats, out_feats=output_feats, aggregator_type='mean')\n",
        "\n",
        "    def forward(self, graph, inputs):\n",
        "        h = self.layer1(graph, inputs)\n",
        "        h = F.relu(h)\n",
        "        h = self.layer2(graph, h)\n",
        "        return h"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-mpR2YUIN8u"
      },
      "source": [
        "### Training and evaluating GCN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0ucu9NVhy-k",
        "outputId": "989627c2-434a-4b3f-efb0-b8a3b608460d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch F1 score: 0.5090068470228363\n",
            "Epoch MicroAvg F1 score: 0.8181008020596099\n",
            "Epoch F1 score: 0.5310026266357524\n",
            "Epoch MicroAvg F1 score: 0.8479684190256114\n",
            "Epoch F1 score: 0.5506878005508433\n",
            "Epoch MicroAvg F1 score: 0.8713868750588456\n",
            "Epoch F1 score: 0.5717969719056701\n",
            "Epoch MicroAvg F1 score: 0.8909023668639052\n",
            "Epoch F1 score: 0.5840364812762884\n",
            "Epoch MicroAvg F1 score: 0.9022762592558735\n",
            "Epoch F1 score: 0.5950968056653602\n",
            "Epoch MicroAvg F1 score: 0.9121266968325791\n",
            "Epoch F1 score: 0.6080208075023104\n",
            "Epoch MicroAvg F1 score: 0.9207503141267277\n",
            "Epoch F1 score: 0.6189932140957974\n",
            "Epoch MicroAvg F1 score: 0.927364337628751\n",
            "Epoch F1 score: 0.626008417342968\n",
            "Epoch MicroAvg F1 score: 0.9316284851713728\n",
            "Epoch F1 score: 0.6326382921277028\n",
            "Epoch MicroAvg F1 score: 0.9356264921743744\n",
            "Epoch F1 score: 0.6361409452359381\n",
            "Epoch MicroAvg F1 score: 0.9380015874415732\n",
            "Epoch F1 score: 0.6405162799422318\n",
            "Epoch MicroAvg F1 score: 0.9406902615959551\n",
            "Epoch F1 score: 0.6453055971755352\n",
            "Epoch MicroAvg F1 score: 0.9433118505852953\n",
            "Epoch F1 score: 0.6491689255017608\n",
            "Epoch MicroAvg F1 score: 0.9454577264575952\n",
            "Epoch F1 score: 0.6521091080627334\n",
            "Epoch MicroAvg F1 score: 0.9470375060035802\n",
            "Epoch F1 score: 0.652190322580721\n",
            "Epoch MicroAvg F1 score: 0.947891684472158\n",
            "Epoch F1 score: 0.6574000423816002\n",
            "Epoch MicroAvg F1 score: 0.9498607242339833\n",
            "Epoch F1 score: 0.66191601115044\n",
            "Epoch MicroAvg F1 score: 0.9515035633582478\n",
            "Epoch F1 score: 0.664489155119197\n",
            "Epoch MicroAvg F1 score: 0.9524140326502257\n",
            "Epoch F1 score: 0.6652915986500852\n",
            "Epoch MicroAvg F1 score: 0.9532029318645097\n",
            "Epoch F1 score: 0.6654232413612264\n",
            "Epoch MicroAvg F1 score: 0.9532483302975107\n",
            "Final F1 score: 0.6654232413612264\n",
            "Final MicroAvg F1 score: 0.9532483302975107\n"
          ]
        }
      ],
      "source": [
        "node_features = g.ndata['feat'].float()\n",
        "node_labels = g.ndata['label'].long()\n",
        "node_features_test = g_test.ndata['feat'].float()\n",
        "node_labels_test = g_test.ndata['label'].long()\n",
        "\n",
        "n_features = node_features.shape[1]\n",
        "n_labels = int(node_labels.max().item() + 1)\n",
        "\n",
        "def evaluate(model, graph, features, labels, final=0):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model(graph, features)\n",
        "        logits = logits\n",
        "        labels = labels\n",
        "        e, indices = torch.max(logits, dim=1)\n",
        "        correct = torch.sum(indices == labels)\n",
        "        \n",
        "        #f1_m = f1_score(indices.cpu().numpy(), labels.cpu().numpy(), average='micro')\n",
        "        f1 = f1_score(indices.cpu().numpy(), labels.cpu().numpy(), average=None)\n",
        "        #f1_w = f1_score(indices.cpu().numpy(), labels.cpu().numpy(), average='weighted')\n",
        "\n",
        "        print(\"Epoch F1 score:\",(f1[0]+f1[1])/2)\n",
        "        print(\"Epoch MicroAvg F1 score:\",f1[1])\n",
        "\n",
        "        if final==1:\n",
        "          print(\"Final F1 score:\",(f1[0]+f1[1])/2)\n",
        "          print(\"Final MicroAvg F1 score:\",f1[1])\n",
        "\n",
        "\n",
        "        return correct.item() * 1.0 / len(labels)\n",
        "\n",
        "\n",
        "model = AML_GCN(input_feats=n_features, hidden_feats=100, output_feats=n_labels)\n",
        "opt = torch.optim.Adam(model.parameters(),lr=0.001)\n",
        "\n",
        "for epoch in range(1000):\n",
        "    model.train()\n",
        "    \n",
        "    logits = model(g, node_features)\n",
        "    \n",
        "    loss = F.cross_entropy(logits, node_labels, weight=torch.tensor([0.7,0.03]))\n",
        "   \n",
        "    if (epoch+1)%50==0:\n",
        "      acc = evaluate(model, g_test, node_features_test, node_labels_test)\n",
        "    \n",
        "    opt.zero_grad()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "\n",
        "acc = evaluate(model, g_test, node_features_test, node_labels_test, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U62092QKIS0i"
      },
      "source": [
        "### Training a new \"custom GCN\" which use an \"Attention Layer\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vd2POE7j4GsZ",
        "outputId": "6180de7a-6e1d-49da-974a-78cdf3aabcab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch F1 score: 0.2743930414082318\n",
            "Epoch MicroAvg F1 score: 0.43900835141711053\n",
            "Epoch F1 score: 0.30061744601665563\n",
            "Epoch MicroAvg F1 score: 0.4895833333333333\n",
            "Epoch F1 score: 0.3170200670317881\n",
            "Epoch MicroAvg F1 score: 0.5190212315546977\n",
            "Epoch F1 score: 0.4999777519126003\n",
            "Epoch MicroAvg F1 score: 0.8849484912024796\n",
            "Epoch F1 score: 0.5053887296078332\n",
            "Epoch MicroAvg F1 score: 0.8922589406971478\n",
            "Epoch F1 score: 0.5108129955376439\n",
            "Epoch MicroAvg F1 score: 0.8993210126354603\n",
            "Epoch F1 score: 0.5145598966168178\n",
            "Epoch MicroAvg F1 score: 0.9044785468211713\n",
            "Epoch F1 score: 0.521179691519089\n",
            "Epoch MicroAvg F1 score: 0.9111120992485214\n",
            "Epoch F1 score: 0.5237106828921976\n",
            "Epoch MicroAvg F1 score: 0.9148097284366279\n",
            "Epoch F1 score: 0.5270564097329438\n",
            "Epoch MicroAvg F1 score: 0.9173922651933702\n",
            "Epoch F1 score: 0.528596922356796\n",
            "Epoch MicroAvg F1 score: 0.9197530864197531\n",
            "Epoch F1 score: 0.5294919668757396\n",
            "Epoch MicroAvg F1 score: 0.9208544373486016\n",
            "Epoch F1 score: 0.5310853215553821\n",
            "Epoch MicroAvg F1 score: 0.9225222056107643\n",
            "Epoch F1 score: 0.5338257142967872\n",
            "Epoch MicroAvg F1 score: 0.9250811474690763\n",
            "Epoch F1 score: 0.5361449018274403\n",
            "Epoch MicroAvg F1 score: 0.9275869612776197\n",
            "Epoch F1 score: 0.5367271614311429\n",
            "Epoch MicroAvg F1 score: 0.9287243805445091\n",
            "Epoch F1 score: 0.5385850780538118\n",
            "Epoch MicroAvg F1 score: 0.9301270021385241\n",
            "Epoch F1 score: 0.5390864833170084\n",
            "Epoch MicroAvg F1 score: 0.9305004144670825\n",
            "Epoch F1 score: 0.5394642254240108\n",
            "Epoch MicroAvg F1 score: 0.9307803026998734\n",
            "Epoch F1 score: 0.5411277880781092\n",
            "Epoch MicroAvg F1 score: 0.9316596931659693\n",
            "Epoch F1 score: 0.5411277880781092\n",
            "Epoch MicroAvg F1 score: 0.9316596931659693\n",
            "Final F1 score: 0.5411277880781092\n",
            "Final MicroAvg F1 score: 0.9316596931659693\n"
          ]
        }
      ],
      "source": [
        "class GAT_GCN(nn.Module):\n",
        "    def __init__(self, input_feats, hidden_feats, output_feats, allow_zero_in_degree = True):\n",
        "        super().__init__()\n",
        "        self.conv1 = dglnn.SAGEConv(\n",
        "            in_feats=input_feats, out_feats=hidden_feats, aggregator_type='mean')\n",
        "        self.conv2 = dglnn.SAGEConv(\n",
        "            in_feats=hidden_feats, out_feats=output_feats, aggregator_type='mean')\n",
        "        \n",
        "        self.layer1 = GATConv(hidden_feats, hidden_feats, 1,allow_zero_in_degree = True)\n",
        "        \n",
        "\n",
        "    def forward(self, graph, inputs):\n",
        "        \n",
        "        h = self.conv1(graph, inputs)\n",
        "        h = F.relu(h)\n",
        "        h = self.layer1(graph,h)\n",
        "        h = torch.squeeze(h,1)\n",
        "        h = self.conv2(graph, h)\n",
        "        return h\n",
        "\n",
        "\n",
        "node_features = g.ndata['feat'].float()\n",
        "node_labels = g.ndata['label'].long()\n",
        "node_features_test = g_test.ndata['feat'].float()\n",
        "node_labels_test = g_test.ndata['label'].long()\n",
        "\n",
        "n_features = node_features.shape[1]\n",
        "n_labels = int(node_labels.max().item() + 1)\n",
        "\n",
        "def evaluate(model, graph, features, labels, final=0):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model(graph, features)\n",
        "        logits = logits\n",
        "        labels = labels\n",
        "        e, indices = torch.max(logits, dim=1)\n",
        "        correct = torch.sum(indices == labels)\n",
        "        \n",
        "        #f1_m = f1_score(indices.cpu().numpy(), labels.cpu().numpy(), average='micro')\n",
        "        f1 = f1_score(indices.cpu().numpy(), labels.cpu().numpy(), average=None)\n",
        "        #f1_w = f1_score(indices.cpu().numpy(), labels.cpu().numpy(), average='weighted')\n",
        "\n",
        "        print(\"Epoch F1 score:\",(f1[0]+f1[1])/2)\n",
        "        print(\"Epoch MicroAvg F1 score:\",f1[1])\n",
        "\n",
        "        if final==1:\n",
        "          print(\"Final F1 score:\",(f1[0]+f1[1])/2)\n",
        "          print(\"Final MicroAvg F1 score:\",f1[1])\n",
        "\n",
        "\n",
        "        return correct.item() * 1.0 / len(labels)\n",
        "\n",
        "\n",
        "model = GAT_GCN(input_feats=n_features, hidden_feats=100, output_feats=n_labels)\n",
        "opt = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(1000):\n",
        "    g = dgl.add_self_loop(g)\n",
        "    model.train()\n",
        "    \n",
        "    logits = model(g, node_features)\n",
        "    \n",
        "    loss = F.cross_entropy(logits, node_labels, weight=torch.tensor([0.7,0.03]))\n",
        "    \n",
        "    if (epoch+1)%50==0:\n",
        "      acc = evaluate(model, g_test, node_features_test, node_labels_test)\n",
        "  \n",
        "    opt.zero_grad()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "\n",
        "\n",
        "acc = evaluate(model, g_test, node_features_test, node_labels_test, 1)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Karan_Bali_File1_GCN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}